{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ETL\n",
    "\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,os.path.join(\"..\",\"..\",\"Resources\",\"AccessInformation\"))\n",
    "\n",
    "from accessinformation import access_token\n",
    "from stravalib import Client , unithelper\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "client = Client(access_token =access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring Data for JSON Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runner information: Raul Maldonado\n"
     ]
    }
   ],
   "source": [
    "print(f'Runner information: {client.get_athlete().firstname} {client.get_athlete().lastname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Athlete Activies\n",
    "\n",
    "Input: client \n",
    "Response: Get activities associated with client from related access_token in client instance above\n",
    "'''\n",
    "def AthleteActivities(client):\n",
    "    return(client.get_activities())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: dictionaryOfDf_toDF\n",
    "\n",
    "Input: dictionary \n",
    "Response: convert dictionary of Data Frames to one single datagrame by the pandas' concat function\n",
    "'''\n",
    "def dictionaryOfDF_toDF(diction):\n",
    "    listOfDataFrames = list(diction.values())\n",
    "    df = pd.concat(listOfDataFrames)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['time', 'heartrate','distance', 'latlng', 'altitude', 'velocity_smooth', \n",
    "                                                'moving', 'grade_smooth', 'temp']\n",
    "\n",
    "\n",
    "'''\n",
    "Function: getActivityStream\n",
    "\n",
    "Input: Activities object from instance of GetActivities from client\n",
    "Response: dictionary of dataframes by required types from list \"types\", seen above.\n",
    "'''\n",
    "def getActivityStream(activitiesObject):\n",
    "    dataFrameDictionary = {}\n",
    "    \n",
    "    #Create Dataframe for each activity in the activities object\n",
    "    for activity in activitiesObject:\n",
    "        try:\n",
    "            '''\n",
    "            Get activity id, name, and types of activity streams from list \"types\"\n",
    "            '''\n",
    "            actID = activity.id\n",
    "            actName = activity.name\n",
    "            streamObject = client.get_activity_streams(actID, types=types, series_type='time')\n",
    "\n",
    "            '''\n",
    "            Instantiate pandas dataframe with required type features. Moreover, Latitude, Longitude, and Date's are engineered\n",
    "            into the dataframe\n",
    "            '''\n",
    "            df=pd.DataFrame( {\"LatLong\": streamObject['latlng'].data, \"Time\": streamObject['time'].data ,\n",
    "                              \"HeartRate\": streamObject['heartrate'].data, \"Distance\": streamObject['distance'].data,\n",
    "                              \"Altitude\": streamObject['altitude'].data,\"Grade_Smooth\": streamObject['grade_smooth'].data,\n",
    "                              'Moving': streamObject['moving'].data ,\"Velocity_Smooth\":streamObject['velocity_smooth'].data})\n",
    "            \n",
    "            \n",
    "            df['Latitude'] = df['LatLong'].apply(lambda x: x[0])\n",
    "            df['Longitude'] = df['LatLong'].apply(lambda x: x[1])\n",
    "            df.drop('LatLong',inplace = True,axis=1)\n",
    "            \n",
    "            df[\"Date\"] = activity.start_date.date()\n",
    "        \n",
    "        except KeyError as e:\n",
    "            continue\n",
    "        \n",
    "        dataFrameDictionary[f'{actName.replace(\" \",\"\")}-{actID}'] = df\n",
    "    return(dataFrameDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dictionary = getActivityStream(AthleteActivities(client))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Dictionary of Dataframes to Json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,values in dataframe_dictionary.items():\n",
    "    values.to_json(f\"../../Data/JSONData/{key}.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = dictionaryOfDF_toDF(dataframe_dictionary)\n",
    "main_df.to_json(f\"../../Data/JSONData/MainDataset.json\", orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, ForeignKey\n",
    "from sqlalchemy import Column, Date, Integer, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///../../Analysis/db/RunningData.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import Running data into the  \"RunningData\" SQLite database table Segments.\n",
    "'''\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Segments(Base):\n",
    "    __tablename__ = \"Segments\"\n",
    "    ids = Column(Integer, primary_key = True)\n",
    "    time = Column(Integer)\n",
    "    distance = Column(Integer)\n",
    "    heartrate = Column(Integer)\n",
    "    altitude = Column(Integer)\n",
    "    grade_smooth = Column(Integer)\n",
    "    moving = Column(Integer)\n",
    "    velocity_smooth = Column(Integer)\n",
    "    latitude = Column(Integer)\n",
    "    longitude = Column(Integer)\n",
    "    \n",
    "    def __init__(self, time, heartrate, distance, altitude, grade_smooth, moving, \\\n",
    "                velocity_smooth, latitude, longitude):\n",
    "        self.time = time\n",
    "        self.heartrate = heartrate\n",
    "        self.distance = distance\n",
    "        self.altitude = altitude \n",
    "        self.grade_smooth = grade_smooth\n",
    "        self.moving = moving\n",
    "        self.velocity_smooth = velocity_smooth\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        \n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "session = Session(bind = engine)\n",
    "for index, rows in main_df.iterrows():\n",
    "    session.add(Segments( time = rows['Time'], heartrate = rows['HeartRate'],distance = rows['Distance'], \n",
    "                         altitude = rows['Altitude'], grade_smooth = rows['Grade_Smooth'], moving = rows['Moving'],\n",
    "                         velocity_smooth = rows['Velocity_Smooth'],latitude = rows['Latitude'],longitude = rows['Longitude']))\n",
    "\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0, 1.4, 146, 25.1, 0, 0, 0, 37.653178, -121.012971),\n",
       " (2, 5, 12.7, 142, 25, 0, 1, 2.3, 37.653181, -121.013099),\n",
       " (3, 8, 21.5, 145, 25.1, 0, 1, 2.5, 37.653181, -121.013199),\n",
       " (4, 15, 42.5, 147, 25.1, 0.2, 1, 3, 37.65315, -121.013433),\n",
       " (5, 18, 50.6, 150, 25.1, 0, 1, 2.9, 37.653147, -121.013524),\n",
       " (6, 20, 56.3, 146, 25.1, 0, 1, 2.8, 37.653143, -121.013589),\n",
       " (7, 22, 61.8, 149, 25.1, 0, 1, 2.8, 37.653142, -121.013651),\n",
       " (8, 26, 73.3, 146, 25.1, 0.2, 1, 2.8, 37.653139, -121.013782),\n",
       " (9, 29, 82.3, 149, 25.1, -0.2, 1, 2.9, 37.653135, -121.013883),\n",
       " (10, 36, 102.9, 149, 25.2, -0.4, 1, 3, 37.653111, -121.014115)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test values are in database\n",
    "[i for i in engine.execute('SELECT * FROM Segments LIMIT 10;')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CCAnalysis-env",
   "language": "python",
   "name": "ccanalysis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
